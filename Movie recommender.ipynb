{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complete_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest.zip'\n",
    "small_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#download locations\n",
    "import os\n",
    "datasets_path = 'datasets'\n",
    "#datasets_path='..'\n",
    "complete_dataset_path = os.path.join(datasets_path,'ml-latest.zip')\n",
    "small_dataset_path = os.path.join(datasets_path,'ml-latest-small.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#procces to download\n",
    "import urllib\n",
    "small_f=urllib.urlretrieve(small_dataset_url,small_dataset_path)\n",
    "complete_f=urllib.urlretrieve(complete_dataset_url,complete_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#extract them into individual folders\n",
    "import zipfile\n",
    "with zipfile.ZipFile(small_dataset_path,'r') as z:\n",
    "    z.extractall(datasets_path)\n",
    "with zipfile.ZipFile(complete_dataset_path,'r') as z:\n",
    "    z.extractall(datasets_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and parsing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loading and parsin datasets\n",
    "#each line in the ratings dataset(ratings.csv) is formatted as:userId,movieId,rating,timestamp\n",
    "#ecah line in the movies (movies.csv) dataset is formatted as:movieId,title,genres, where genres has format: Genre1|Genre2..\n",
    "#tags.csv has the format: userId,movieId,tag,timestamp\n",
    "#links.csv has the format:movieId,imdbId,tmdbId\n",
    "#Parsing the movies and ratings files yields two RDDs:\n",
    "###1. For each line in the ratings dataset, we create a tuple of (UserID,MovieID,Rating). We do not need the timestamp\n",
    "###2. For each line in the movies dataset, we create a tuple of (MovieID,Title)\n",
    "#Llet's load the raw ratings data. We need to filter out the header\n",
    "#small_ratings_file = '/home/cloudera/Documents/ML_SPARK/ml-latest-small/ratings.csv'\n",
    "#small_ratings_raw_data = sc.textFile('file:///home/cloudera/Documents/ML_SPARK/ml-latest-small/ratings.csv')\n",
    "small_ratings_file = os.path.join(datasets_path,'ml-latest-small','ratings.csv')\n",
    "small_ratings_raw_data = sc.textFile(small_ratings_file)\n",
    "small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parse the raw data into a new RDD\n",
    "small_ratings_data = small_ratings_raw_data.filter(lambda line:line!=small_ratings_raw_data_header)\\\n",
    "    .map(lambda line:line.split(\",\")).map(lambda tokens:(tokens[0],tokens[1],tokens[2])).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'1', u'31', u'2.5'), (u'1', u'1029', u'3.0'), (u'1', u'1061', u'3.0')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking userId,movieId,rating tuples\n",
    "small_ratings_data.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'1', u'Toy Story (1995)'),\n",
       " (u'2', u'Jumanji (1995)'),\n",
       " (u'3', u'Grumpier Old Men (1995)')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the same with movies.csv file (MovieId,Title)\n",
    "small_movies_file = os.path.join(datasets_path,'ml-latest-small','movies.csv')\n",
    "small_movies_raw_data = sc.textFile(small_movies_file)\n",
    "small_movies_raw_data_header = small_movies_raw_data.take(1)[0]\n",
    "small_movies_data = small_movies_raw_data.filter(lambda line:line!=small_movies_raw_data_header)\\\n",
    "    .map(lambda line:line.split(\",\")).map(lambda tokens:(tokens[0],tokens[1])).cache()\n",
    "small_movies_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Collaborative filtering - Selecting Alternating Least Squares (ALS) parameters using the small dataset\n",
    "#In order to determine the best ALS parameters, we will use the small dataset\n",
    "training_RDD,validation_RDD,test_RDD = small_ratings_data.randomSplit([6,2,2], seed=0L)\n",
    "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0],x[1]))\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0],x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 4 the RMSE is 0.955539621074\n",
      "For rank 8 the RMSE is 0.961337186578\n",
      "For rank 12 the RMSE is 0.955331367921\n",
      "The best model was trained with the rank 12\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "seed = 5L\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [4,8,12]\n",
    "errors = [0,0,0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(training_RDD,rank,seed=seed,iterations=iterations,lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r:((r[0],r[1]),r[2]))\n",
    "    rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]),int(r[1])),float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print 'For rank %s the RMSE is %s' % (rank,error)\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "print 'The best model was trained with the rank %s' % best_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((63, 2987), (4.5, 3.230462074482902)),\n",
       " ((353, 4387), (2.5, 2.5613337280152444)),\n",
       " ((472, 2014), (3.0, 2.819901745338644))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare real values with predictions\n",
    "rates_and_preds.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.952936492902\n"
     ]
    }
   ],
   "source": [
    "#let's test the selected model\n",
    "model = ALS.train(training_RDD,best_rank,seed=seed,iterations=iterations,lambda_=regularization_parameter)\n",
    "predictions = model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0],r[1]),r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]),int(r[1])),float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "print 'For testing data the RMSE is %s' % (error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the complete dataset to build the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24404096 recommendations in the complete dataset\n"
     ]
    }
   ],
   "source": [
    "complete_ratings_file = os.path.join(datasets_path,'ml-latest','ratings.csv')\n",
    "complete_ratings_raw_data = sc.textFile(complete_ratings_file)\n",
    "sc.setCheckpointDir('/home/vcp/Documents/ML_SPARK/Recomm_system/checkpoint/')\n",
    "complete_ratings_raw_data_header = complete_ratings_raw_data.take(1)[0]\n",
    "complete_ratings_data = complete_ratings_raw_data.filter(lambda line: line!= complete_ratings_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens:(int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache()\n",
    "print 'There are %s recommendations in the complete dataset' % (complete_ratings_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train the complete dataset\n",
    "training_RDD,test_RDD = complete_ratings_data.randomSplit([7,3],seed=0L)\n",
    "complete_model = ALS.train(training_RDD,best_rank,seed=seed,iterations=iterations,lambda_=regularization_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py\", line 883, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py\", line 1040, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "Py4JNetworkError: Error while receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o629.partitions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-e23fbe617f00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train the complete dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtraining_RDD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_RDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplete_ratings_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandomSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0L\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcomplete_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mALS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_RDD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_rank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularization_parameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/mllib/recommendation.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cls, ratings, rank, iterations, lambda_, blocks, nonnegative, seed)\u001b[0m\n\u001b[1;32m    270\u001b[0m           \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \"\"\"\n\u001b[0;32m--> 272\u001b[0;31m         model = callMLlibFunc(\"trainALSModel\", cls._prepare(ratings), rank, iterations,\n\u001b[0m\u001b[1;32m    273\u001b[0m                               lambda_, blocks, nonnegative, seed)\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mMatrixFactorizationModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/mllib/recommendation.py\u001b[0m in \u001b[0;36m_prepare\u001b[0;34m(cls, ratings)\u001b[0m\n\u001b[1;32m    227\u001b[0m             raise TypeError(\"Ratings should be represented by either an RDD or a DataFrame, \"\n\u001b[1;32m    228\u001b[0m                             \"but got %s.\" % type(ratings))\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mfirst\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m         \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRDD\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \"\"\"\n\u001b[0;32m-> 1328\u001b[0;31m         \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \"\"\"\n\u001b[1;32m   1279\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m         \u001b[0mtotalParts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetNumPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m         \u001b[0mpartsScanned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mgetNumPartitions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetNumPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2388\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prev_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2390\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m             raise Py4JError(\n\u001b[1;32m    326\u001b[0m                 \u001b[0;34m\"An error occurred while calling {0}{1}{2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 format(target_id, \".\", name))\n\u001b[0m\u001b[1;32m    328\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o629.partitions"
     ]
    }
   ],
   "source": [
    "#train the complete dataset\n",
    "training_RDD,test_RDD = complete_ratings_data.randomSplit([7,3],seed=0L)\n",
    "complete_model = ALS.train(training_RDD,best_rank,seed=seed,iterations=iterations,lambda_=regularization_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.817353031097\n"
     ]
    }
   ],
   "source": [
    "#test on the testing set\n",
    "test_for_predict_RDD= test_RDD.map(lambda x: (x[0],x[1]))\n",
    "predictions = complete_model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0],r[1]),r[2]))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]),int(r[1])),float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "print 'For testing data the RMSE is %s' % (error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Big impreovement by only using the dataset with more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 40110 movies in the complete dataset\n"
     ]
    }
   ],
   "source": [
    "#making recommendations\n",
    "#Let's first load the movies complete file for later use\n",
    "complete_movies_raw_data = sc.textFile('file:///home/cloudera/Documents/ML_SPARK/ml-latest/movies.csv')\n",
    "complete_movies_raw_data_header = complete_movies_raw_data.take(1)[0]\n",
    "complete_movies_data = complete_movies_raw_data.filter(lambda line: line!=complete_movies_raw_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache()\n",
    "complete_movies_titles = complete_movies_data.map(lambda x: (int(x[0]),x[1]))\n",
    "print 'There are %s movies in the complete dataset' % (complete_movies_titles.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#as we want to give recommendations of movies with a certain minimum number of ratings, we need to count the number of\n",
    "#ratings per movie\n",
    "def get_counts_and_averages(ID_and_ratings_tuple):\n",
    "    nratings = len(ID_and_ratings_tuple[1])\n",
    "    return ID_and_ratings_tuple[0], (nratings,float(sum(float(x) for x in ID_and_ratings_tuple[1]))/nratings)\n",
    "movie_ID_with_ratings_RDD = (complete_ratings_data.map(lambda x: (x[1],x[2])).groupByKey())\n",
    "movie_ID_with_avg_ratings_RDD= movie_ID_with_ratings_RDD.map(get_counts_and_averages)\n",
    "movie_rating_counts_RDD= movie_ID_with_avg_ratings_RDD.map(lambda x: (int(x[0]),x[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user ratings: [(0, 260, 4), (0, 1, 3), (0, 16, 3), (0, 25, 4), (0, 32, 4), (0, 335, 1), (0, 379, 1), (0, 858, 5), (0, 50, 4)]\n"
     ]
    }
   ],
   "source": [
    "#Adding new user ratings\n",
    "#Now we need to rate some movies for the new user. We will put them in a new RDD and we will use the user ID 0,\n",
    "#that is not assigned in the MovieLens dataset.\n",
    "new_user_ID = 0\n",
    "#the format of each line is (userID,movieID,rating)\n",
    "new_user_ratings = [\n",
    "    (0,260,4), #Star Wars\n",
    "    (0,1,3),   #Toy Story\n",
    "    (0,16,3),  #Casino\n",
    "    (0,25,4),  #Leaving Las Vegas\n",
    "    (0,32,4),  #Twelve Monkeys\n",
    "    (0,335,1), #Flinstones, the\n",
    "    (0,379,1), #Timecop\n",
    "    (0,858,5), #Godfather, The\n",
    "    (0,50,4)   #Usual Suspects, The\n",
    "]\n",
    "new_user_ratings_RDD = sc.parallelize(new_user_ratings)\n",
    "print 'New user ratings: %s' % new_user_ratings_RDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now we add them to the data we will use to train our recommender model. We use Spark's union() for this\n",
    "complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model train in 465.71 seconds\n"
     ]
    }
   ],
   "source": [
    "#And finally we train the ALS model using all the parameters we selected before (when using the small dataset)\n",
    "from time import time\n",
    "t0=time()\n",
    "new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD,best_rank,seed=seed,iterations=iterations,\n",
    "                             lambda_=regularization_parameter)\n",
    "tt= time() - t0\n",
    "print 'New model train in %s seconds' % round(tt,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#It took a while. We would need to repeat that every time a user adds new ratings. Ideally we would do this in batches,\n",
    "#and not every single rating that ocmes into the system for every user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting top recommendations\n",
    "#Let's now get some recommendations! For that we will get an RDD with all the movies the new user hasn't rated yet. We\n",
    "#will pu them together with the model to predict ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_user_ratings_ids = map(lambda x: x[1],new_user_ratings)#get just movie IDs. Keep just those not on the ID list\n",
    "new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids)\\\n",
    "                              .map(lambda x: (new_user_ID,x[0])))\n",
    "#use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for movies\n",
    "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(67704, ((1.5516317518367981, u'Too Many Girls (1940)'), 2)),\n",
       " (30721, ((2.54679722756578, u'Hell Is for Heroes (1962)'), 54)),\n",
       " (92163, ((2.911432418448211, u'Fados (2007)'), 5))]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we have our recommendations ready. Now ew can print out the 25 movies with the highest predicted ratings. And join\n",
    "#them with the movies RDD to get the titles, and ratings count in order to get movies with a minimum of counts.\n",
    "#transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
    "new_user_recommendations_rating_RDD= new_user_recommendations_RDD.map(lambda x: (x.product,x.rating))\n",
    "new_user_recommendations_rating_title_and_count_RDD=new_user_recommendations_rating_RDD\\\n",
    "    .join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
    "new_user_recommendations_rating_title_and_count_RDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we need to flat this down a bit in order to have (Title,Rating,Ratings Count)\n",
    "new_user_recommendations_rating_title_and_count_RDD=new_user_recommendations_rating_title_and_count_RDD\\\n",
    "    .map(lambda r: (r[1][0][1],r[1][0][0],r[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP recommended movies (with more than 25 reviews):\n",
      "(u'Beastie Boys: Sabotage (1994)', 4.230875480408205, 28)\n",
      "(u\"Long Night's Journey Into Day (2000)\", 4.180721740547556, 35)\n",
      "(u'Pulp Fiction (1994)', 4.16112621133422, 83523)\n",
      "(u'Heimat - A Chronicle of Germany (Heimat - Eine deutsche Chronik) (1984)', 4.091140734620533, 31)\n",
      "(u'\"Godfather: Part II', 4.05359763667845, 34508)\n",
      "(u'Frozen Planet (2011)', 4.011833420838773, 239)\n",
      "(u'The War (2007)', 3.979016636774192, 34)\n",
      "(u'O.J.: Made in America (2016)', 3.930796489509352, 41)\n",
      "(u'Long Way Round (2004)', 3.928982437959138, 29)\n",
      "(u'Wanderers (2014)', 3.8950620320889637, 41)\n",
      "(u'Apocalypse Now (1979)', 3.8912439666328598, 26465)\n",
      "(u'Milius (2013)', 3.8507362893279593, 29)\n",
      "(u'Band of Brothers (2001)', 3.8487608892220133, 7833)\n",
      "(u'Goodfellas (1990)', 3.8418881491963535, 32025)\n",
      "(u'Pinchcliffe Grand Prix (Fl\\xe5klypa Grand Prix) (1975)', 3.831509606489127, 28)\n",
      "(u'\"Classe am\\xe9ricaine', 3.8211027927815797, 32)\n",
      "(u'Bill Hicks: Sane Man (1989)', 3.82039377992956, 26)\n",
      "(u'Fight Club (1999)', 3.8152733508446817, 54376)\n",
      "(u'\"Electric Boogaloo: The Wild', 3.8114992600626127, 46)\n",
      "(u'Reservoir Dogs (1992)', 3.8058036395612693, 32836)\n",
      "(u'Death on the Staircase (Soup\\xe7ons) (2004)', 3.804126187476426, 63)\n",
      "(u'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)', 3.79822226827286, 27089)\n",
      "(u'City of God (Cidade de Deus) (2002)', 3.7938076949700474, 18237)\n",
      "(u'\"Two Escobars', 3.7878187105545305, 56)\n",
      "(u'Taxi Driver (1976)', 3.7865554891623034, 29909)\n"
     ]
    }
   ],
   "source": [
    "#finally, get the highest rated recommendations for the new user, filtering out movies with less than 25 ratings\n",
    "top_movies=new_user_recommendations_rating_title_and_count_RDD.filter(lambda r:r[2]>=25)\\\n",
    "    .takeOrdered(25,key=lambda x:-x[1])\n",
    "print ('TOP recommended movies (with more than 25 reviews):\\n%s') % '\\n'.join(map(str,top_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=0, product=500, rating=1.9548165387003076)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting individual ratings\n",
    "#Another useful usecase is getting the predicted rating for a particular movie for a given user\n",
    "my_movie = sc.parallelize([(0,500)]) #Quiz Show (1994)\n",
    "individual_movie_rating_RDD = new_ratings_model.predictAll(my_movie)\n",
    "individual_movie_rating_RDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#persisting the model\n",
    "from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "model_path = \"file:///home/cloudera/Documents/ML_SPARK/Recomm_system/movie_lens_als\"\n",
    "model.save(sc,model_path)\n",
    "#same_model=MatrixFactorizationModel.load(sc,model_path) --> to load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
